# llm_service.py
import httpx
import json  # ğŸ‘ˆ å¿…é¡»å¯¼å…¥ json
from typing import List, Dict, AsyncGenerator
from app.config import BASE_URL, DEEPSEEK_API_KEY

HEADERS = {
    "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
    "Content-Type": "application/json",
}

async def call_llm(model: str, messages: List[Dict[str, str]]) -> str:
    # ç¡®ä¿ URL æ‹¼æ¥æ­£ç¡®ï¼Œé˜²æ­¢å‡ºç° //v1/v1 çš„æƒ…å†µ
    api_url = f"{BASE_URL.rstrip('/')}/v1/chat/completions"
    
    async with httpx.AsyncClient(timeout=60) as client:
        resp = await client.post(
            api_url,
            headers=HEADERS,
            json={
                "model": model,
                "messages": messages,
                "temperature": 0.7,
                "stream": False # æ˜¾å¼å…³é—­æµ
            },
        )
        resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]


async def call_llm_stream(
    model: str,
    messages: List[Dict[str, str]],
) -> AsyncGenerator[str, None]:
    
    api_url = f"{BASE_URL.rstrip('/')}/v1/chat/completions"

    async with httpx.AsyncClient(timeout=120) as client: # æµå¼å»ºè®®è¶…æ—¶è®¾é•¿ä¸€ç‚¹
        async with client.stream(
            "POST",
            api_url,
            headers=HEADERS,
            json={
                "model": model,
                "messages": messages,
                "stream": True, # å¼€å¯æµ
                "temperature": 0.7, 
            },
        ) as response:
            async for line in response.aiter_lines():
                if not line:
                    continue
                
                # 1. å»é™¤ data: å‰ç¼€
                if line.startswith("data:"):
                    line = line[5:].strip() # å»æ‰ 'data:' (5ä¸ªå­—ç¬¦)
                
                # 2. æ£€æŸ¥ç»“æŸæ ‡è®°
                if line == "[DONE]":
                    break
                
                # 3. è§£æ JSON å¹¶æå–æ–‡å­—
                try:
                    chunk = json.loads(line)
                    # OpenAI æ ¼å¼çš„æ ‡å‡†æå–è·¯å¾„ï¼šchoices[0].delta.content
                    delta = chunk["choices"][0].get("delta", {})
                    content = delta.get("content", "")
                    
                    if content:
                        yield content  # ğŸ‘ˆ å…³é”®ï¼šåª yield çº¯æ–‡æœ¬ï¼
                        
                except json.JSONDecodeError:
                    continue
                except Exception as e:
                    # print(f"è§£æé”™è¯¯: {e}") 
                    continue